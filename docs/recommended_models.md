# –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ Ollama –¥–ª—è AILLM

–≠—Ç–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –≤—ã–±–æ—Ä—É –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã –ø—Ä–æ–µ–∫—Ç–∞ AILLM.

> **–ò—Å—Ç–æ—á–Ω–∏–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π**: –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–µ–π, –∞–Ω–∞–ª–∏–∑ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤, [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/), –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–∞—è –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è Ollama.

---

## üìä –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π

| –ó–∞–¥–∞—á–∞ | –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –º–æ–¥–µ–ª–∏ | VRAM | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|--------|---------------------|------|------------|
| **–ß–∞—Ç (—Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫)** | gemma3:12b, qwen2.5:14b | 8-16 GB | –õ—É—á—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º |
| **–ö–æ–¥** | qwen2.5-coder:14b, deepseek-coder-v2:16b | 10-20 GB | –í—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ |
| **–†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è/Reasoning** | qwen3:14b, deepseek-r1:14b | 10-18 GB | Thinking mode |
| **–ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã** | gemma3:1b, qwen2.5:1.5b | 2-4 GB | –î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ |
| **–ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö** | gemma3:12b, qwen2.5:14b | 8-16 GB | –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã |

---

## üéØ –î–µ—Ç–∞–ª—å–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–¥–∞—á–∞–º

### üí¨ –ß–∞—Ç –∏ –æ–±—â–µ–Ω–∏–µ (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞)

**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

```bash
ollama pull gemma3:12b
```

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | –ö–∞—á–µ—Å—Ç–≤–æ RU | –°–∫–æ—Ä–æ—Å—Ç—å | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|--------|--------|------|-------------|----------|------------|
| **gemma3:12b** ‚≠ê | 8 GB | 10-12 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –°—Ä–µ–¥–Ω—è—è | **–õ—É—á—à–∏–π –≤—ã–±–æ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞** |
| gemma3:4b | 3 GB | 4-6 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –ë—ã—Å—Ç—Ä–∞—è | –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ |
| qwen2.5:14b | 9 GB | 12-16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –°—Ä–µ–¥–Ω—è—è | –û—Ç–ª–∏—á–Ω–æ –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –¥–∏–∞–ª–æ–≥–æ–≤ |
| qwen2.5:7b | 4.7 GB | 6-8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –ë—ã—Å—Ç—Ä–∞—è | –•–æ—Ä–æ—à–µ–µ –∫–∞—á–µ—Å—Ç–≤–æ, –±—ã—Å—Ç—Ä—ã–π |
| llama3.3:70b | 43 GB | 48+ GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ú–µ–¥–ª–µ–Ω–Ω–∞—è | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ (–Ω—É–∂–µ–Ω –º–æ—â–Ω—ã–π GPU) |

**‚ö†Ô∏è –ù–ï —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–ª—è —á–∞—Ç–∞:**
- `llama3.2:3b` ‚Äî —Å–º–µ—à–∏–≤–∞–µ—Ç —è–∑—ã–∫–∏, —Å–ª–∞–±–æ–µ —Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º
- `llama3.2:1b` ‚Äî —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
- `mistral:7b` ‚Äî —Å–ª–∞–±–∞—è –ø–æ–¥–¥–µ—Ä–∂–∫–∞ —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞

---

### üíª –ù–∞–ø–∏—Å–∞–Ω–∏–µ –∏ –∞–Ω–∞–ª–∏–∑ –∫–æ–¥–∞

**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

```bash
ollama pull qwen2.5-coder:14b
```

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | –ö–∞—á–µ—Å—Ç–≤–æ –∫–æ–¥–∞ | –Ø–∑—ã–∫–∏ | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|--------|--------|------|---------------|-------|------------|
| **qwen2.5-coder:14b** ‚≠ê | 9 GB | 12-16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –í—Å–µ | **–õ—É—á—à–∏–π –¥–ª—è –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è** |
| qwen2.5-coder:7b | 4.7 GB | 6-8 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –í—Å–µ | –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å |
| deepseek-coder-v2:16b | 10 GB | 14-18 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –í—Å–µ | –û—Ç–ª–∏—á–µ–Ω –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á |
| codellama:13b | 7.4 GB | 10-12 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | Python, JS, C++ | –•–æ—Ä–æ—à –¥–ª—è Python |
| starcoder2:7b | 4 GB | 6-8 GB | ‚≠ê‚≠ê‚≠ê | Python, JS | –ë—ã—Å—Ç—Ä—ã–π, –Ω–æ –º–µ–Ω–µ–µ —Ç–æ—á–Ω—ã–π |

**–î–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–±–æ–ª—å—à–∏–µ —Ñ–∞–π–ª—ã):**
```bash
ollama pull gemma3:12b  # 128K –∫–æ–Ω—Ç–µ–∫—Å—Ç, —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π KV-–∫—ç—à
```

> **–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ**: Qwen –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –±–æ–ª—å—à–µ KV-–∫—ç—à–∞. –î–ª—è –±–æ–ª—å—à–∏—Ö –∫–æ–¥–æ–≤—ã—Ö –±–∞–∑ gemma3 –º–æ–∂–µ—Ç –±—ã—Ç—å —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–µ–µ.

---

### üß† –†–∞—Å—Å—É–∂–¥–µ–Ω–∏—è –∏ Thinking Mode

**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

```bash
ollama pull qwen3:14b
```

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | Reasoning | Thinking Mode | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|--------|--------|------|-----------|---------------|------------|
| **qwen3:14b** ‚≠ê | 9 GB | 12-16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ù–∞—Ç–∏–≤–Ω—ã–π | **–õ—É—á—à–∏–π –¥–ª—è reasoning** |
| qwen3:8b | 5 GB | 7-10 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –ù–∞—Ç–∏–≤–Ω—ã–π | –ë—ã—Å—Ç—Ä–µ–µ, —á—É—Ç—å —Ö—É–∂–µ –∫–∞—á–µ—Å—Ç–≤–æ |
| deepseek-r1:14b | 9 GB | 12-16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ù–∞—Ç–∏–≤–Ω—ã–π | –û—Ç–ª–∏—á–Ω–æ–µ reasoning |
| deepseek-r1:7b | 4.7 GB | 6-9 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –ù–∞—Ç–∏–≤–Ω—ã–π | –•–æ—Ä–æ—à–∏–π –±–∞–ª–∞–Ω—Å |
| llama3.3:70b | 43 GB | 48+ GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –≠–º—É–ª—è—Ü–∏—è | –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ |

---

### ‚ö° –ë—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏ (–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è, –≤–∞–ª–∏–¥–∞—Ü–∏—è)

**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

```bash
ollama pull gemma3:1b
ollama pull qwen2.5:1.5b
```

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | –°–∫–æ—Ä–æ—Å—Ç—å | –ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ |
|--------|--------|------|----------|------------|
| **gemma3:1b** ‚≠ê | 0.8 GB | 2-3 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Ä—É—Å—Å–∫–∏–π |
| **qwen2.5:1.5b** ‚≠ê | 1.1 GB | 2-4 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, –∫–æ–¥ |
| llama3.2:1b | 0.7 GB | 2-3 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –¢–æ–ª—å–∫–æ –∞–Ω–≥–ª–∏–π—Å–∫–∏–π |
| phi-3:3.8b | 2.3 GB | 4-5 GB | ‚≠ê‚≠ê‚≠ê‚≠ê | –ë–∞–ª–∞–Ω—Å —Å–∫–æ—Ä–æ—Å—Ç—å/–∫–∞—á–µ—Å—Ç–≤–æ |

**–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ AILLM:**
- `LLMClassifier` ‚Äî –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
- `TwoStageProcessor` ‚Äî –±—ã—Å—Ç—Ä–∞—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
- `TaskRouter` ‚Äî –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–æ–≤

---

### üìä –ê–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö

**–û—Å–Ω–æ–≤–Ω–∞—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:**

```bash
ollama pull gemma3:12b
ollama pull qwen2.5:14b
```

| –ú–æ–¥–µ–ª—å | –†–∞–∑–º–µ—Ä | VRAM | –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤—ã–≤–æ–¥ | JSON | –ü—Ä–∏–º–µ—á–∞–Ω–∏—è |
|--------|--------|------|-------------------------|------|------------|
| **gemma3:12b** ‚≠ê | 8 GB | 10-12 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –û—Ç–ª–∏—á–Ω—ã–π –¥–ª—è —Ç–∞–±–ª–∏—Ü –∏ –∞–Ω–∞–ª–∏–∑–∞ |
| qwen2.5:14b | 9 GB | 12-16 GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –°–ª–æ–∂–Ω—ã–π –∞–Ω–∞–ª–∏–∑ |
| llama3.3:70b | 43 GB | 48+ GB | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | –ú–∞–∫—Å–∏–º—É–º –¥–ª—è —Å–ª–æ–∂–Ω—ã—Ö –∑–∞–¥–∞—á |

---

## üñ•Ô∏è –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—é

### –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (8 GB VRAM)

```bash
# –ù–∞–±–æ—Ä –¥–ª—è 8 GB GPU (RTX 3070, RTX 4060)
ollama pull gemma3:4b      # –ß–∞—Ç
ollama pull qwen2.5-coder:7b  # –ö–æ–¥
ollama pull gemma3:1b      # –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–¥–∞—á–∏
```

### –†–µ–∫–æ–º–µ–Ω–¥—É–µ–º–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (16 GB VRAM)

```bash
# –ù–∞–±–æ—Ä –¥–ª—è 16 GB GPU (RTX 4080, RTX 3090)
ollama pull gemma3:12b         # –ß–∞—Ç (–æ—Å–Ω–æ–≤–Ω–∞—è)
ollama pull qwen2.5-coder:14b  # –ö–æ–¥ (–æ—Å–Ω–æ–≤–Ω–∞—è)
ollama pull qwen3:14b          # Reasoning
ollama pull gemma3:1b          # –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–¥–∞—á–∏
ollama pull qwen2.5:1.5b       # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
```

### –ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (24+ GB VRAM)

```bash
# –ù–∞–±–æ—Ä –¥–ª—è 24+ GB GPU (RTX 4090, A100)
ollama pull gemma3:12b         # –ß–∞—Ç
ollama pull qwen2.5-coder:14b  # –ö–æ–¥
ollama pull deepseek-coder-v2:16b  # –°–ª–æ–∂–Ω—ã–π –∫–æ–¥
ollama pull qwen3:14b          # Reasoning
ollama pull deepseek-r1:14b    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π reasoning
ollama pull gemma3:1b          # –ë—ã—Å—Ç—Ä—ã–µ –∑–∞–¥–∞—á–∏
ollama pull qwen2.5:1.5b       # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
```

### –°–µ—Ä–≤–µ—Ä–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è (48+ GB VRAM)

```bash
# –ù–∞–±–æ—Ä –¥–ª—è —Å–µ—Ä–≤–µ—Ä–æ–≤ (A100 80GB, H100)
ollama pull llama3.3:70b       # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
ollama pull qwen2.5:72b        # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞
ollama pull gemma3:12b         # –ë—ã—Å—Ç—Ä—ã–π —á–∞—Ç
ollama pull qwen2.5-coder:14b  # –ö–æ–¥
```

---

## üîß –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º–æ–≥–æ –Ω–∞–±–æ—Ä–∞

### –ë—ã—Å—Ç—Ä—ã–π —Å—Ç–∞—Ä—Ç (–æ–¥–∏–Ω —Å–∫—Ä–∏–ø—Ç)

```bash
#!/bin/bash
# install_recommended_models.sh

echo "üöÄ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã—Ö –º–æ–¥–µ–ª–µ–π –¥–ª—è AILLM..."

# –û—Å–Ω–æ–≤–Ω—ã–µ –º–æ–¥–µ–ª–∏
ollama pull gemma3:12b
ollama pull qwen2.5-coder:14b
ollama pull qwen3:14b

# –ë—ã—Å—Ç—Ä—ã–µ –º–æ–¥–µ–ª–∏
ollama pull gemma3:1b
ollama pull qwen2.5:1.5b

echo "‚úÖ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!"
ollama list
```

### –ü—Ä–æ–≤–µ—Ä–∫–∞ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π

```bash
ollama list
```

---

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –≤ AILLM

–ü–æ—Å–ª–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏ –º–æ–¥–µ–ª–µ–π, –æ–±–Ω–æ–≤–∏—Ç–µ `backend/config/config.yaml`:

```yaml
llm:
  providers:
    ollama:
      enabled: true
      default_model: gemma3:12b  # –î–ª—è —á–∞—Ç–∞
      recommended_models:
        chat:
          - gemma3:12b
          - gemma3:4b
          - qwen2.5:14b
        code:
          - qwen2.5-coder:14b
          - qwen2.5-coder:7b
          - deepseek-coder-v2:16b
        reasoning:
          - qwen3:14b
          - deepseek-r1:14b
        analysis:
          - gemma3:12b
          - qwen2.5:14b
        fast:
          - gemma3:1b
          - qwen2.5:1.5b
```

---

## üìà –ë–µ–Ω—á–º–∞—Ä–∫–∏ –∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è

### –ö–∞—á–µ—Å—Ç–≤–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ (—Å—É–±—ä–µ–∫—Ç–∏–≤–Ω–∞—è –æ—Ü–µ–Ω–∫–∞)

```
gemma3:12b      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà 95%
qwen2.5:14b     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 90%
llama3.3:70b    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë 90%
qwen2.5:7b      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë 80%
gemma3:4b       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë 75%
mistral:7b      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 50%
llama3.2:3b     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë 40%  ‚ùå –ù–µ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è
```

### –°–∫–æ—Ä–æ—Å—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (tokens/sec –Ω–∞ RTX 4090)

```
gemma3:1b       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ~150 tok/s
qwen2.5:1.5b    ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë ~120 tok/s
gemma3:4b       ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë ~80 tok/s
qwen2.5:7b      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ~60 tok/s
gemma3:12b      ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ~40 tok/s
qwen2.5:14b     ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ~35 tok/s
```

---

## üîÑ –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π

–ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∏ –ø—Ä–æ–≤–µ—Ä—è–π—Ç–µ –Ω–∞–ª–∏—á–∏–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π:

```bash
# –û–±–Ω–æ–≤–∏—Ç—å –≤—Å–µ –º–æ–¥–µ–ª–∏
ollama list | tail -n +2 | awk '{print $1}' | xargs -I {} ollama pull {}

# –û–±–Ω–æ–≤–∏—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –º–æ–¥–µ–ª—å
ollama pull gemma3:12b
```

---

## üÜò –†–µ—à–µ–Ω–∏–µ –ø—Ä–æ–±–ª–µ–º

### –ú–æ–¥–µ–ª—å —Å–º–µ—à–∏–≤–∞–µ—Ç —è–∑—ã–∫–∏
**–†–µ—à–µ–Ω–∏–µ**: –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `gemma3:12b` –≤–º–µ—Å—Ç–æ `llama3.2:3b`

### –ú–æ–¥–µ–ª—å –≤—ã–¥—É–º—ã–≤–∞–µ—Ç —Ñ–∞–∫—Ç—ã
**–†–µ—à–µ–Ω–∏–µ**: 
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ 7B+ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
2. –í–∫–ª—é—á–∏—Ç–µ –≤–µ–±-–ø–æ–∏—Å–∫ –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
3. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ `duckduckgo-search`: `pip install duckduckgo-search`

### –ú–µ–¥–ª–µ–Ω–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è
**–†–µ—à–µ–Ω–∏–µ**: 
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ –¥–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –∑–∞–¥–∞—á
2. –í–∫–ª—é—á–∏—Ç–µ GPU offloading –≤ Ollama
3. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ `TwoStageProcessor` –¥–ª—è –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏

### Out of Memory
**–†–µ—à–µ–Ω–∏–µ**:
1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –º–æ–¥–µ–ª–∏ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞
2. –£–º–µ–Ω—å—à–∏—Ç–µ `num_ctx` –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö Ollama
3. –ó–∞–∫—Ä–æ–π—Ç–µ –¥—Ä—É–≥–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É—é—â–∏–µ GPU

---

## üìö –ü–æ–ª–µ–∑–Ω—ã–µ —Å—Å—ã–ª–∫–∏

- [Ollama Model Library](https://ollama.com/library)
- [r/LocalLLaMA](https://www.reddit.com/r/LocalLLaMA/)
- [LLM Benchmarks](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
- [AILLM Documentation](./README.md)

---

## üéÆ Multi-GPU –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è

### Ollama + –Ω–µ—Å–∫–æ–ª—å–∫–æ GPU

Ollama –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –º–æ–¥–µ–ª—å –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º GPU. –î–ª—è –æ–ø—Ç–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–±–æ—Ç—ã:

```bash
# –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –¥–æ—Å—Ç—É–ø–Ω—ã–µ GPU
nvidia-smi

# –£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ GPU –¥–ª—è Ollama (–≤ ~/.bashrc –∏–ª–∏ –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ)
export CUDA_VISIBLE_DEVICES=0,1,2  # –î–ª—è 3 GPU
```

### –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è AILLM –¥–ª—è multi-GPU

–í `backend/config/config.yaml`:

```yaml
performance:
  gpu:
    enabled: true
    multi_gpu: true
    devices:
      - cuda:0  # RTX 3090 #1
      - cuda:1  # RTX 3090 #2
      - cuda:2  # RTX 3090 #3
    memory_per_gpu_gb: 24
    load_balancing: round_robin
```

### Capacity –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É GPU

| GPU | VRAM | Capacity | –ú–æ–¥–µ–ª–∏ |
|-----|------|----------|--------|
| 1x RTX 3090 | 24 GB | ~20 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ | –î–æ 14B –º–æ–¥–µ–ª–µ–π |
| 2x RTX 3090 | 48 GB | ~36 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ | –î–æ 30B –º–æ–¥–µ–ª–µ–π |
| 3x RTX 3090 | 72 GB | ~52 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ | –î–æ 70B –º–æ–¥–µ–ª–µ–π |

### –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –¥–ª—è 3x RTX 3090 (72 GB VRAM)

```bash
# –¢–µ–ø–µ—Ä—å –¥–æ—Å—Ç—É–ø–Ω—ã –±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏!
ollama pull llama3.3:70b      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ
ollama pull qwen2.5:72b       # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ 70B
ollama pull deepseek-v2:67b   # –û—Ç–ª–∏—á–Ω—ã–π –¥–ª—è –∫–æ–¥–∞

# –ü–ª—é—Å —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –Ω–∞–±–æ—Ä
ollama pull gemma3:12b
ollama pull qwen2.5-coder:14b
ollama pull qwen3:14b
ollama pull gemma3:1b
```

### –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ GPU

```bash
# –ü–æ—Å—Ç–æ—è–Ω–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥
watch -n 1 nvidia-smi

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ AILLM
nvidia-smi --query-gpu=utilization.gpu,memory.used,memory.total --format=csv -l 1
```

---

## üìà –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–µ—Å—É—Ä—Å–æ–≤

AILLM –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ –¥–æ—Å—Ç—É–ø–Ω—ã–º —Ä–µ—Å—É—Ä—Å–∞–º:

1. **–ê–≤—Ç–æ-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GPU** ‚Äî —Å–∏—Å—Ç–µ–º–∞ –æ–±–Ω–∞—Ä—É–∂–∏–≤–∞–µ—Ç –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ –∫–∞—Ä—Ç—ã
2. **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π capacity** ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ —Ä–∞—Å—Ç—ë—Ç —Å —Ä–µ—Å—É—Ä—Å–∞–º–∏
3. **–í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π** ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –ø–æ–¥ –∑–∞–¥–∞—á—É
4. **Load balancing** ‚Äî —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è–µ—Ç –Ω–∞–≥—Ä—É–∑–∫—É –º–µ–∂–¥—É GPU

–ü—Ä–∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–∏ GPU –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—å Ollama –∏ AILLM ‚Äî —Å–∏—Å—Ç–µ–º–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ–±–Ω–∞—Ä—É–∂–∏—Ç –Ω–æ–≤—ã–µ —Ä–µ—Å—É—Ä—Å—ã.

---

*–ü–æ—Å–ª–µ–¥–Ω–µ–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ: –¥–µ–∫–∞–±—Ä—å 2025*

