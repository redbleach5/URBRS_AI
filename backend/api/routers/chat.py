"""
Chat router - –ü—Ä–æ—Å—Ç–æ–π —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —á–∞—Ç –±–µ–∑ –∞–≥–µ–Ω—Ç–æ–≤
–î–ª—è –±—ã—Å—Ç—Ä—ã—Ö –æ—Ç–≤–µ—Ç–æ–≤, —à—É—Ç–æ–∫, –Ω–æ–≤–æ—Å—Ç–µ–π, –∫–æ–º–∞–Ω–¥ Linux –∏ —Ç.–¥.
"""

from fastapi import APIRouter, HTTPException, Request
from pydantic import BaseModel
from typing import Optional, Dict, Any, List
from datetime import datetime

from backend.core.logger import get_logger
from backend.llm.base import LLMMessage

logger = get_logger(__name__)

router = APIRouter()


class ChatMessage(BaseModel):
    role: str  # "user" –∏–ª–∏ "assistant"
    content: str


class ChatRequest(BaseModel):
    message: str
    history: Optional[List[ChatMessage]] = None
    mode: Optional[str] = "general"  # general, ide, research
    context: Optional[Dict[str, Any]] = None
    model: Optional[str] = None  # –í—ã–±—Ä–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å (None = –∞–≤—Ç–æ–≤—ã–±–æ—Ä)
    provider: Optional[str] = None  # –í—ã–±—Ä–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä


class ChatResponse(BaseModel):
    success: bool
    message: str
    error: Optional[str] = None
    warning: Optional[str] = None  # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    metadata: Optional[Dict[str, Any]] = None


# –°–∏—Å—Ç–µ–º–Ω—ã–µ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ä–µ–∂–∏–º–æ–≤
SYSTEM_PROMPTS = {
    "general": """–¢—ã ‚Äî —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π AI-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢—ã –º–æ–∂–µ—à—å:
- –û—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –ª—é–±—ã–µ –≤–æ–ø—Ä–æ—Å—ã
- –®—É—Ç–∏—Ç—å –∏ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—Ç—å –Ω–µ–ø—Ä–∏–Ω—É–∂–¥—ë–Ω–Ω—É—é –±–µ—Å–µ–¥—É
- –û–±—ä—è—Å–Ω—è—Ç—å –∫–æ–º–∞–Ω–¥—ã Linux, —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
- –ü–æ–º–æ–≥–∞—Ç—å —Å –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã–º–∏ –∑–∞–¥–∞—á–∞–º–∏
- –î–∞–≤–∞—Ç—å —Å–æ–≤–µ—Ç—ã –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

–í–ê–ñ–ù–´–ï –ü–†–ê–í–ò–õ–ê:
1. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ù–µ –∏—Å–ø–æ–ª—å–∑—É–π —Å–ª–æ–≤–∞ –∏–∑ –¥—Ä—É–≥–∏—Ö —è–∑—ã–∫–æ–≤ (–≤—å–µ—Ç–Ω–∞–º—Å–∫–æ–≥–æ, —Ö–∏–Ω–¥–∏, –∏—Ç–∞–ª—å—è–Ω—Å–∫–æ–≥–æ –∏ —Ç.–¥.)
2. –ï—Å–ª–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–ø—Ä–∞—à–∏–≤–∞–µ—Ç –æ –Ω–æ–≤–æ—Å—Ç—è—Ö –∏–ª–∏ –∞–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Å–æ–±—ã—Ç–∏—è—Ö:
   - –ï—Å–ª–∏ —Ç–µ–±–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω –≤–µ–±-–∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –µ–≥–æ
   - –ï—Å–ª–∏ –≤–µ–±-–∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –ù–ï–¢ ‚Äî —á–µ—Å—Ç–Ω–æ —Å–∫–∞–∂–∏: "–£ –º–µ–Ω—è –Ω–µ—Ç –¥–æ—Å—Ç—É–ø–∞ –∫ –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –Ω–æ–≤–æ—Å—Ç—è–º. –ú–æ–∏ –∑–Ω–∞–Ω–∏—è –æ–≥—Ä–∞–Ω–∏—á–µ–Ω—ã –¥–∞—Ç–æ–π –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏."
   - –ù–ò–ö–û–ì–î–ê –Ω–µ –≤—ã–¥—É–º—ã–≤–∞–π –Ω–æ–≤–æ—Å—Ç–∏, —Å–æ–±—ã—Ç–∏—è –∏–ª–∏ —Ñ–∞–∫—Ç—ã!
3. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç ‚Äî —Ç–∞–∫ –∏ —Å–∫–∞–∂–∏, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é.

–ë—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –ø–æ–ª–µ–∑–Ω—ã–º. –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ–¥–∑–∏ –≥–¥–µ —É–º–µ—Å—Ç–Ω–æ.
–§–æ—Ä–º–∞—Ç–∏—Ä—É–π –æ—Ç–≤–µ—Ç—ã —Å markdown –¥–ª—è –ª—É—á—à–µ–π —á–∏—Ç–∞–µ–º–æ—Å—Ç–∏.
–¢–µ–∫—É—â–∞—è –¥–∞—Ç–∞: {current_date}""",

    "ide": """–¢—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫. –¢—ã –º–æ–∂–µ—à—å:
- –ü–∏—Å–∞—Ç—å –∏ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–æ–¥ –Ω–∞ –ª—é–±—ã—Ö —è–∑—ã–∫–∞—Ö
- –û—Ç–ª–∞–∂–∏–≤–∞—Ç—å –∏ –∏—Å–ø—Ä–∞–≤–ª—è—Ç—å –æ—à–∏–±–∫–∏
- –û–±—ä—è—Å–Ω—è—Ç—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –ø—Ä–æ–µ–∫—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
- –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∫–æ–¥–∞
- –†–µ–≤—å—é–∏—Ç—å –∫–æ–¥ –∏ –ø—Ä–µ–¥–ª–∞–≥–∞—Ç—å —É–ª—É—á—à–µ–Ω–∏—è
- –ü–æ–º–æ–≥–∞—Ç—å —Å Git, Docker, CI/CD –∏ DevOps

–û—Ç–≤–µ—á–∞–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏ –≥—Ä–∞–º–æ—Ç–Ω–æ, —Å –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∫–æ–¥–∞ –∫–æ–≥–¥–∞ —É–º–µ—Å—Ç–Ω–æ.
–ò—Å–ø–æ–ª—å–∑—É–π markdown —Å –ø–æ–¥—Å–≤–µ—Ç–∫–æ–π —Å–∏–Ω—Ç–∞–∫—Å–∏—Å–∞ –¥–ª—è –∫–æ–¥–∞.
–ë—É–¥—å –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ —Ç–æ—á–µ–Ω –≤ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–µ—Ç–∞–ª—è—Ö.""",

    "research": """–¢—ã ‚Äî —ç–∫—Å–ø–µ—Ä—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫. –¢—ã –º–æ–∂–µ—à—å:
- –ì–ª—É–±–æ–∫–æ –∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–º—ã –∏ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—Ç—å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è
- –°—Ä–∞–≤–Ω–∏–≤–∞—Ç—å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏ –∏ –ø–æ–¥—Ö–æ–¥—ã
- –ò—Å–∫–∞—Ç—å –∏ –æ–±–æ–±—â–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
- –°–æ–∑–¥–∞–≤–∞—Ç—å —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç—á—ë—Ç—ã
- –ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ç—Ä–µ–Ω–¥—ã –∏ –ø—Ä–æ–≥–Ω–æ–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–∑–≤–∏—Ç–∏–µ

–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–π –¥–µ—Ç–∞–ª—å–Ω—ã–µ, —Ö–æ—Ä–æ—à–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã.
–£–∫–∞–∑—ã–≤–∞–π –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ.
–ò—Å–ø–æ–ª—å–∑—É–π —Ç–∞–±–ª–∏—Ü—ã, —Å–ø–∏—Å–∫–∏ –∏ –¥—Ä—É–≥–æ–µ —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏."""
}


def get_system_prompt(mode: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è —Ä–µ–∂–∏–º–∞ —Å –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–æ–π –¥–∞—Ç—ã"""
    prompt = SYSTEM_PROMPTS.get(mode, SYSTEM_PROMPTS["general"])
    current_date = datetime.now().strftime("%d %B %Y, %H:%M")
    return prompt.format(current_date=current_date)


@router.post("/chat", response_model=ChatResponse)
async def chat(request: Request, chat_request: ChatRequest):
    """
    –ü—Ä–æ—Å—Ç–æ–π —á–∞—Ç –±–µ–∑ –∞–≥–µ–Ω—Ç–æ–≤ ‚Äî –Ω–∞–ø—Ä—è–º—É—é —á–µ—Ä–µ–∑ LLM.
    –ë—ã—Å—Ç—Ä—ã–µ –æ—Ç–≤–µ—Ç—ã –¥–ª—è –ø–æ–≤—Å–µ–¥–Ω–µ–≤–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤.
    –ù–ï –±–ª–æ–∫–∏—Ä—É–µ—Ç —Å–ª–æ–∂–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ ‚Äî —Ç–æ–ª—å–∫–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
    """
    logger.info(f"Chat request: mode={chat_request.mode}, message_length={len(chat_request.message)}")
    
    engine = request.app.state.engine
    
    if not engine:
        raise HTTPException(status_code=503, detail="–î–≤–∏–∂–æ–∫ –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    llm_manager = engine.llm_manager
    
    if not llm_manager:
        raise HTTPException(status_code=503, detail="LLM –ø—Ä–æ–≤–∞–π–¥–µ—Ä –Ω–µ –¥–æ—Å—Ç—É–ø–µ–Ω")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–ª–æ–∂–Ω–æ—Å—Ç—å –∑–∞–¥–∞—á–∏ (–ù–ï –±–ª–æ–∫–∏—Ä—É–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ!)
    complexity_warning = None
    complexity_info = None
    try:
        from backend.core.complexity_analyzer import get_complexity_analyzer
        analyzer = get_complexity_analyzer()
        complexity_info = analyzer.analyze(
            task=chat_request.message,
            model=chat_request.model,
            task_type=chat_request.mode
        )
        
        if complexity_info.should_warn:
            complexity_warning = complexity_info.warning_message
            logger.info(f"Chat complexity warning: {complexity_info.level.value}, ~{complexity_info.estimated_minutes:.1f} min")
    except Exception as e:
        logger.debug(f"Complexity analysis failed (non-critical): {e}")
    
    try:
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è
        messages = [
            LLMMessage(
                role="system",
                content=get_system_prompt(chat_request.mode or "general")
            )
        ]
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å
        if chat_request.history:
            for msg in chat_request.history[-10:]:  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 10 —Å–æ–æ–±—â–µ–Ω–∏–π
                messages.append(LLMMessage(
                    role=msg.role,
                    content=msg.content
                ))
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—É—â–µ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
        messages.append(LLMMessage(
            role="user",
            content=chat_request.message
        ))
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω—É–∂–µ–Ω –ª–∏ –ø–æ–∏—Å–∫ –≤ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–µ
        needs_search = any(keyword in chat_request.message.lower() for keyword in [
            "–Ω–æ–≤–æ—Å—Ç–∏", "news", "–ø–æ—Å–ª–µ–¥–Ω–∏–µ", "–∞–∫—Ç—É–∞–ª—å–Ω—ã–µ", "—Å–µ–≥–æ–¥–Ω—è",
            "—Ü–µ–Ω—ã", "–∫—É—Ä—Å", "–ø–æ–≥–æ–¥–∞", "—Å–æ–±—ã—Ç–∏—è"
        ])
        
        web_context = ""
        if needs_search and engine.tool_registry:
            try:
                logger.info("Chat: Performing web search for context")
                search_result = await engine.tool_registry.execute_tool(
                    "web_search",
                    {"query": chat_request.message, "max_results": 5}
                )
                
                if search_result.success and search_result.result:
                    results = search_result.result.get("results", [])
                    if results:
                        web_context = "\n\nüì∞ **–ù–∞–π–¥–µ–Ω–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞:**\n"
                        for i, result in enumerate(results[:3], 1):
                            title = result.get('title', '').strip()
                            snippet = result.get('snippet', '').strip()
                            url = result.get('url', '').strip()
                            web_context += f"\n{i}. **{title}**\n{snippet}\n[–ò—Å—Ç–æ—á–Ω–∏–∫]({url})\n"
                        
                        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫ —Å–æ–æ–±—â–µ–Ω–∏—é
                        messages[-1] = LLMMessage(
                            role="user",
                            content=f"{chat_request.message}\n\n{web_context}\n\n–ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è –æ—Ç–≤–µ—Ç–∞."
                        )
            except Exception as e:
                logger.warning(f"Chat web search failed: {e}")
        
        # –£–º–Ω—ã–π –≤—ã–±–æ—Ä –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–æ–±—â–µ–Ω–∏—è
        model_to_use = chat_request.model
        provider_to_use = chat_request.provider
        
        # –ï—Å–ª–∏ –º–æ–¥–µ–ª—å –ù–ï —É–∫–∞–∑–∞–Ω–∞ —è–≤–Ω–æ, –≤—ã–±–∏—Ä–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
        if not model_to_use and complexity_info:
            ollama_provider = llm_manager.providers.get("ollama")
            if ollama_provider:
                # –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –∏—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å
                if complexity_info.level.value in ["trivial", "simple"]:
                    # –ò—â–µ–º –±—ã—Å—Ç—Ä—É—é –º–æ–¥–µ–ª—å –∏–∑ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö
                    fast_models = ollama_provider.recommended_models.get("fast", [])
                    available = getattr(ollama_provider, '_available_models', [])
                    
                    for fast_model in fast_models:
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏
                        if any(fast_model in m for m in available):
                            model_to_use = next((m for m in available if fast_model in m), None)
                            if model_to_use:
                                logger.info(f"Chat: Simple message -> using fast model: {model_to_use}")
                                break
                    
                    # Fallback –Ω–∞ gemma3:1b –∏–ª–∏ qwen2.5:1.5b –µ—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏
                    if not model_to_use:
                        for fallback in ["gemma3:1b", "qwen2.5:1.5b", "llama3.2:1b"]:
                            if any(fallback in m for m in available):
                                model_to_use = next((m for m in available if fallback in m), None)
                                if model_to_use:
                                    logger.info(f"Chat: Using fallback fast model: {model_to_use}")
                                    break
        
        # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω–∞ –º–æ–¥–µ–ª—å —è–≤–Ω–æ, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ—ë
        if model_to_use:
            ollama_provider = llm_manager.providers.get("ollama")
            if ollama_provider:
                # –í—Ä–µ–º–µ–Ω–Ω–æ –º–µ–Ω—è–µ–º –º–æ–¥–µ–ª—å –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                original_model = ollama_provider.default_model
                ollama_provider.default_model = model_to_use
                logger.info(f"Chat: Using model: {model_to_use}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = await llm_manager.generate(
            messages=messages,
            provider_name=provider_to_use,
            model=model_to_use,
            temperature=0.7,
            max_tokens=2000
        )
        
        # –í–æ—Å—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –µ—Å–ª–∏ –º–µ–Ω—è–ª–∏
        if model_to_use:
            ollama_provider = llm_manager.providers.get("ollama")
            if ollama_provider and 'original_model' in locals():
                ollama_provider.default_model = original_model
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º, –±—ã–ª–∞ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
        used_fast_model = (
            complexity_info and 
            complexity_info.level.value in ["trivial", "simple"] and
            response.model and
            any(x in response.model.lower() for x in ["1b", "1.5b", "2b"])
        )
        
        return ChatResponse(
            success=True,
            message=response.content,
            warning=complexity_warning,  # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ –æ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ (–µ—Å–ª–∏ –±—ã–ª–æ)
            metadata={
                "model": response.model,
                "provider": getattr(response, 'provider', 'ollama'),
                "mode": chat_request.mode,
                "has_thinking": getattr(response, 'thinking', None) is not None,
                "thinking": getattr(response, 'thinking', None),
                "web_search_used": bool(web_context),
                "complexity_level": complexity_info.level.value if complexity_info else None,
                "estimated_minutes": complexity_info.estimated_minutes if complexity_info else None,
                "smart_model_selection": True,  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —á—Ç–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª—Å—è —É–º–Ω—ã–π –≤—ã–±–æ—Ä
                "used_fast_model": used_fast_model  # –ë—ã–ª–∞ –ª–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞ –±—ã—Å—Ç—Ä–∞—è –º–æ–¥–µ–ª—å
            }
        )
        
    except Exception as e:
        logger.error(f"Chat error: {e}", exc_info=True)
        error_message = str(e)
        
        if "timeout" in error_message.lower():
            error_message = "–ü—Ä–µ–≤—ã—à–µ–Ω–æ –≤—Ä–µ–º—è –æ–∂–∏–¥–∞–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –µ—â—ë —Ä–∞–∑."
        elif "connection" in error_message.lower():
            error_message = "–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ LLM. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
        
        return ChatResponse(
            success=False,
            message="",
            error=error_message
        )

